{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Econometrics I: Homework 2\n",
    "\n",
    "## David Černý, Jan Hrušák"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(quantmod)\n",
    "library(rugarch)\n",
    "library(dplyr)\n",
    "\n",
    "\n",
    "set.seed(38848152)\n",
    "\n",
    "data = read.csv(\"symbols2.csv\")\n",
    "\n",
    "symbols = as.vector(sample(data$Symbol, 100, replace = FALSE))\n",
    "\n",
    "\n",
    "DownloadYahoo <- function(symbol, from, to = Sys.Date())\n",
    "{\n",
    "  # Package Check\n",
    "  if (!requireNamespace(\"quantmod\", quietly = TRUE)) \n",
    "  {\n",
    "    stop(\"Package 'quantmod' must be installed. Use install.packages('quantmod').\")\n",
    "  }\n",
    "  \n",
    "  # Download data from yahoo finance\n",
    "  tryCatch(\n",
    "  {\n",
    "    getSymbols(symbol, from = from, to = to, auto.assign = TRUE)\n",
    "    data <- get(symbol)\n",
    "    names(data) = unname(sapply(names(data), sub, pattern = \".*\\\\.\", replacement = \"\"))\n",
    "    return(data)\n",
    "  }, error = function(e) \n",
    "  {\n",
    "    message(\"Skipping due to error: \", e$message)\n",
    "    return(NULL)\n",
    "  })\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from = as.Date('2020-01-01')\n",
    "to = as.Date('2022-11-01')\n",
    "\n",
    "dfs = list()\n",
    "pricesList = list()\n",
    "\n",
    "#names(prices) = symbols\n",
    "for (i in 1 : length(symbols))\n",
    "{\n",
    "  \n",
    "  df = DownloadYahoo(symbols[i], from, to)\n",
    "  # Skip to the next iteration if df is NULL (= unsuccessful import)\n",
    "  if (is.null(df)) next\n",
    "  # Assign using double square brackets for list\n",
    "  dfs[[i]] = df \n",
    "}\n",
    "names(dfs) = symbols\n",
    "\n",
    "# Create new List without the invalid symbols\n",
    "for (symbol in symbols)\n",
    "{\n",
    "  if(!is.null(dfs[[symbol]]))\n",
    "  {\n",
    "    pricesList[[symbol]] = dfs[[symbol]]\n",
    "  }\n",
    "}\n",
    "length(pricesList)\n",
    "prices = data.frame(\"Date\" = index(pricesList[[1]]))\n",
    "# Create Data Frame of prices\n",
    "for (validSymbol in names(pricesList))\n",
    "{\n",
    "  prices[validSymbol] = as.vector(pricesList[[validSymbol]]$Adjusted)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### 1)\n",
    "# Compute Log Returns\n",
    "logReturns = data.frame(\"Date\" = prices$Date[2:length(prices$Date)])\n",
    "for (validSymbol in names(pricesList))\n",
    "{\n",
    "  logReturns[validSymbol] = diff(log(as.vector(pricesList[[validSymbol]]$Adjusted)))\n",
    "}\n",
    "summary(logReturns)\n",
    "# Delete the column with almost 500 NAs\n",
    "logReturns = select(logReturns, -COL)\n",
    "sum(is.na(logReturns))\n",
    "validSymbols = colnames(logReturns)[2:ncol(logReturns)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the logarithmic returns of each symbol in our collection, then we\n",
    "omitted all NAs in the new dataframe, since otherwise it would not be \n",
    "compatible with the following processes. Due to this data cleaning we removed no row, since all NAs was included in the column of symbol \"COL\". In case of just a few NAs it would be more suitable to delete all rows containing NAs, but since all of them are in one column, we should delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(rugarch)\n",
    "### 2)\n",
    "# For each stock, estimate the parameters of a GARCH(1, 1) model:\n",
    "garchModels = list()\n",
    "\n",
    "for (validSymbol in validSymbols)\n",
    "{\n",
    "  spec = ugarchspec(variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1)), \n",
    "                    mean.model = list(armaOrder = c(0, 0), include.mean = TRUE), \n",
    "                    distribution.model = \"norm\")\n",
    "  garchModels[[validSymbol]] = ugarchfit(spec, logReturns[, validSymbol])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimated the GARCH(1,1) model for each symbol of our dataframe using the \n",
    "\"rugarch\" package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### 3)\n",
    "# Plotting Garch(1,1) coefs\n",
    "alphas = sapply(garchModels, function(model) coef(model)[\"alpha1\"])\n",
    "betas = sapply(garchModels, function(model) coef(model)[\"beta1\"])\n",
    "alphasPlusBetas = alphas + betas\n",
    "\n",
    "par(mfrow = c(1, 3))\n",
    "hist(alphas, main = \"Histogram of alphas\", xlab = \"Alpha\")\n",
    "hist(betas, main = \"Histogram of betas\", xlab = \"Beta\")\n",
    "hist(alphasPlusBetas, main = \"Histogram of alphas + betas\", xlab = \"Alpha + Beta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha_i$ represents the impact of the squared residuals (innovations) on the \n",
    "conditional variance. A higher value of $\\alpha_i$ indicates that the volatility\n",
    "is more sensitive to recent market shocks.\n",
    "\n",
    "$\\beta_i$ represents the persistence of the conditional variance (the impact of past\n",
    "volatility on current volatility). A higher value of $\\beta_i$ indicates that the\n",
    "volatility is more persistent and takes longer to dissipate.\n",
    "\n",
    "The sum $\\alpha_i$ + $\\beta_i$ measures the rate at which the response to volatility decays\n",
    "over time. A value close to 1 indicates a slower decay and more persistence\n",
    "in volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### 4)\n",
    "# Find the minimum and maximum values of alpha_i, beta_i, and alpha_i + beta_i. Comment briefly:\n",
    "min_alpha = min(alphas)\n",
    "max_alpha = max(alphas)\n",
    "min_beta = min(betas)\n",
    "max_beta = max(betas)\n",
    "min_alphaPlusBeta = min(alphasPlusBetas)\n",
    "max_alphaPlusBeta = max(alphasPlusBetas)\n",
    "\n",
    "cat(\"Minimum alpha:\", min_alpha, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value is very close to zero (practically zero).\n",
    "This indicates that for the stock with the lowest alpha, the impact of recent\n",
    "market shocks on volatility is very minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Maximum alpha:\", max_alpha, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximal alpha is relatively high.\n",
    "This suggests that for the stock with the highest alpha, the volatility is highly sensitive to recent market shocks, and new information or innovations have a significant impact on the conditional variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Minimum beta:\", min_beta, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimal value of beta is relativelly low but still positive.\n",
    "This implies that for the stock with the lowest beta, the persistence of volatility is relatively low, and past volatility has a smaller impact on current volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Maximum beta:\", max_beta, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximal beta is almost 1.\n",
    "This indicates that for the stock with the highest beta, the volatility is highly persistent, and past volatility has a significant impact on current volatility. The conditional variance is heavily influenced by its own lagged values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Minimum alpha + beta:\", min_alphaPlusBeta, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimal value of the sum is relatively low.\n",
    "This suggests that for the stock with the lowest alpha + beta, the response to volatility decays relatively quickly over time, and the impact of past shocks on future volatility diminishes faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Maximum alpha + beta:\", max_alphaPlusBeta, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to maximal beta, the maximal value of the sum is also almost 1.\n",
    "This indicates that for the stock with the highest alpha + beta, the response to volatility decays slowly over time, and the impact of past shocks on future volatility persists for a longer period. The conditional variance exhibits strong persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### 5)\n",
    "marketVolatility = data.frame(\"Date\" = logReturns$Date)\n",
    "\n",
    "for (i in 1:nrow(logReturns))\n",
    "{\n",
    "  dayVolatilities = sapply(garchModels, function(model) if (!is.null(model)) sigma(model)[i] else NA)\n",
    "  marketVolatility$Median[i] = median(dayVolatilities, na.rm = TRUE)\n",
    "  marketVolatility$Quantile95[i] = quantile(dayVolatilities, 0.95, na.rm = TRUE)\n",
    "  marketVolatility$Quantile05[i] = quantile(dayVolatilities, 0.05, na.rm = TRUE)\n",
    "}\n",
    "\n",
    "plot(marketVolatility$Date, marketVolatility$Median, type = \"l\", xlab = \"Date\", ylab = \"Market Volatility\",\n",
    "     main = \"Market Volatility and Quantiles\", ylim = range(marketVolatility[, 2:4], na.rm = TRUE))\n",
    "lines(marketVolatility$Date, marketVolatility$Quantile95, col = \"blue\")\n",
    "lines(marketVolatility$Date, marketVolatility$Quantile05, col = \"red\")\n",
    "legend(\"topright\", legend = c(\"Median\", \"95% Quantile\", \"5% Quantile\"),\n",
    "       col = c(\"black\", \"blue\", \"red\"), lty = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the estimated market volatility and its \"low\" and \"high\" quantiles.\n",
    "In the figure we can see that the volatility appears to be most of the time \n",
    "quite stable, although, there are also visible at least two high volatility \n",
    "clusters - we might assume that the first cluster (the most significant one) \n",
    "is likely to be impacted by the covid19 crisis hit. The explanation for the \n",
    "second one does not seem to be apparent.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the data again, since we used also our second seed number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(quantmod)\n",
    "\n",
    "# seed\n",
    "set.seed(53600945)\n",
    "\n",
    "# generate 100 random integers from the range 1 to 377\n",
    "random_indices <- sample(1:377, 100, replace = FALSE)\n",
    "\n",
    "# read tickers\n",
    "symbols_df <- read.csv(\"symbols2.csv\", sep = \",\", header = TRUE)\n",
    "\n",
    "#print(symbols_df)\n",
    "\n",
    "#print(random_indices)\n",
    "\n",
    "\n",
    "# select tickers based on the generated random numbers\n",
    "selected_tickers <- symbols_df$Symbol[random_indices]\n",
    "\n",
    "\n",
    "print(selected_tickers)\n",
    "\n",
    "# start and end dates for the data download\n",
    "start_date <- as.Date(\"2020-01-01\")\n",
    "end_date <- as.Date(\"2022-10-31\")\n",
    "\n",
    "# list to store the stock data\n",
    "stock_data_list <- list()\n",
    "\n",
    "# loop through the selected tickers and download the stock price data\n",
    "for(ticker in selected_tickers) {\n",
    "  # tryCatch fction is used to ignore errors (if the stock is not available etc.)\n",
    "  stock_data <- tryCatch({\n",
    "    getSymbols(ticker, src = 'yahoo', from = start_date, to = end_date, auto.assign = FALSE)\n",
    "  }, error = function(e) NULL)\n",
    "  \n",
    "  # if stock data was downloaded, add it to the list\n",
    "  if (!is.null(stock_data)) {\n",
    "    stock_data_list[[ticker]] <- stock_data\n",
    "  }\n",
    "}\n",
    "\n",
    "#print(head(stock_data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the log returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# fction to compute logarithmic returns\n",
    "compute_log_returns <- function(stock_prices) {\n",
    "  \n",
    "  log_returns <- diff(log(Cl(stock_prices)))\n",
    "  return(log_returns)\n",
    "}\n",
    "\n",
    "# a list to store the logarithmic returns for each stock\n",
    "log_returns_list <- list()\n",
    "\n",
    "# loop through each of the stock's data in 'stock_data_list' to compute the logarithmic returns\n",
    "for(ticker in names(stock_data_list)) {\n",
    "  stock_prices <- stock_data_list[[ticker]]\n",
    "  log_returns <- compute_log_returns(stock_prices)\n",
    "  log_returns_list[[ticker]] <- log_returns\n",
    "}\n",
    "\n",
    "#print(log_returns_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute mean log returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# combine all the logarithmic returns into one dataframe\n",
    "# each column represents a stock, and each row represents a date\n",
    "combined_log_returns <- do.call(merge, c(log_returns_list, all = TRUE))\n",
    "\n",
    "# mean logarithmic return for each date\n",
    "mean_log_returns <- rowMeans(combined_log_returns, na.rm = TRUE)\n",
    "\n",
    "# convert the mean logarithmic returns to a dataframe \n",
    "mean_log_returns_df <- data.frame(Date = index(combined_log_returns), MeanLogReturn = mean_log_returns)\n",
    "\n",
    "head(mean_log_returns_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARMA identification and estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean the data from missing observations\n",
    "clean_data <- na.omit(mean_log_returns_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "plot.ts(clean_data$MeanLogReturn, ylab = NA, main = 'mean_log_returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see a pattern typical for financial returns data, that are very likely mean stationary. There seem to be clusters of higher volatility, with the most significant one at the beginning of our data, which covers mainly the year 2020. We might argue that this was due to the onset of COVID-19 and related economic uncertainty. The mean stationarity of the series is further tested using ADF and KPSS tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#install.packages('tseries')\n",
    "\n",
    "rets = clean_data$MeanLogReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tseries)\n",
    "\n",
    "\n",
    "Box.test(rets, type = 'Ljung-Box')\n",
    "\n",
    "adf.test(rets, k = 1)\n",
    "\n",
    "kpss.test(rets, null = 'Level')\n",
    "kpss.test(rets, null = 'Trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ljung-Box Q test rejects the null hypothesis of no autocorrelation. This suggests that past values might have a predictive power on future values in our series.\n",
    "\n",
    "Based on the ADF test, we reject the null hypothesis of unit root; suggesting mean stationarity. Since ADF test tests just for a specific form of non-stationarity (unit root) we conduct a KPSS test. \n",
    "\n",
    "Based on the KPSS test, we do not reject the null hypothesis of neither level (around a mean) or trend (around a trend of the series) stationarity. All on the 5% sign. level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "\n",
    "# autocorrelation and partial autocorrelation fctions\n",
    "acf(rets)\n",
    "pacf(rets)\n",
    "\n",
    "#print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plotted PACF we estimate AR(2), AR(4), and AR(7). We chose those based on the displayed significant lags. \n",
    "\n",
    "We suspect that AR(9) might work the best, however it is also a model of a probably too high order, possibly leading to overfitting our data.\n",
    "\n",
    "Since it is not clear from the plots whether to use AR or MA model, we later estimate MA models and the combination of both model types as well. For now we focus on the AR models only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets_ar2 <- Arima(rets, order = c(2, 0, 0))\n",
    "summary (rets_ar2)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets_ar2$residuals, main = NA)\n",
    "pacf(rets_ar2$residuals, main = NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Box.test(rets_ar2$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "\n",
    "Box.test(rets_ar2$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "\n",
    "Box.test(rets_ar2$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets_ar2$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the PACF of the estimated AR(2) model we can see that it does not 'smoothen' the autocorellation well. This can be seen also on the low p-values of the Box-Ljung tests at the higher lags. Hence, there is still a room for a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets_ar4 <- Arima(rets, order = c(4, 0, 0))\n",
    "summary (rets_ar4)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets_ar4$residuals, main = NA)\n",
    "pacf(rets_ar4$residuals, main = NA)\n",
    "\n",
    "Box.test(rets_ar4$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets_ar4$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets_ar4$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets_ar4$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly as for the AR(2) model, the AR(4) does not have a very good fit based on both PACF and the B-L tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets_ar7 <- Arima(rets, order = c(7, 0, 0))\n",
    "summary (rets_ar7)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets_ar7$residuals, main = NA)\n",
    "pacf(rets_ar7$residuals, main = NA)\n",
    "\n",
    "Box.test(rets_ar7$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets_ar7$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets_ar7$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets_ar7$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AR(7) model seems to have much better fit based on all the p-values above the 5% sign. threshold of the B-L tests for various lags. However if one looks at the PACF there are still two significant lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets_ar9 <- Arima(rets, order = c(9, 0, 0))\n",
    "summary (rets_ar9)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets_ar9$residuals, main = NA)\n",
    "pacf(rets_ar9$residuals, main = NA)\n",
    "\n",
    "Box.test(rets_ar9$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets_ar9$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets_ar9$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets_ar9$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the AR(9) works quite well with all the B-L tests p-values almost 1 and one barely significant lag on the PACF. However we continue with model identification since we want as parsimonious model as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the ACF of our returns data plotted earlier we suspect an MA(1) process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets_ma1 <- Arima(rets, order = c(0, 0, 1))\n",
    "summary (rets_ma1)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets_ma1$residuals, main = NA)\n",
    "pacf(rets_ma1$residuals, main = NA)\n",
    "\n",
    "Box.test(rets_ma1$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets_ma1$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets_ma1$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets_ma1$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does not look very well based on both the B-L tests for higher lags as well as the plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the auto-arima fction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "auto.arima(rets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we try the suggested MA(2) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets_ma2 <- Arima(rets, order = c(0, 0, 2), include.mean = FALSE)\n",
    "summary (rets_ma2)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets_ma2$residuals, main = NA)\n",
    "pacf(rets_ma2$residuals, main = NA)\n",
    "\n",
    "\n",
    "Box.test(rets_ma2$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets_ma2$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets_ma2$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets_ma2$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, however, behaves not very differently from the MA(1) model. It does not have much better fit.\n",
    "\n",
    "Therefore, we try a combination of the AR and MA models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets_arma42 <- Arima(rets, order = c(4, 0, 2))\n",
    "summary (rets_arma42)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets_arma42$residuals, main = NA)\n",
    "pacf(rets_arma42$residuals, main = NA)\n",
    "\n",
    "Box.test(rets_arma42$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets_arma42$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets_arma42$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets_arma42$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ARMA(4,2) model seems to be the best model based on the ACF, PACF, as well as the tests (all p-values much higher than 0.05). ACF as well as PACF have no significant lags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compare the estimated models based on the AIC and BIC criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "models <- 7\n",
    "criteria <- matrix(ncol = 2, nrow = models)\n",
    "colnames(criteria) <- c('AIC', 'BIC')\n",
    "rownames(criteria) <- c('AR(2)','AR(4)', 'AR(7)', 'AR(9)','ARMA(4,2)','MA(1)','MA(2)')\n",
    "\n",
    "criteria[1, 1] <- rets_ar2$aic\n",
    "criteria[1, 2] <- rets_ar2$bic\n",
    "criteria[2, 1] <- rets_ar4$aic\n",
    "criteria[2, 2] <- rets_ar4$bic\n",
    "criteria[3, 1] <- rets_ar7$aic\n",
    "criteria[3, 2] <- rets_ar7$bic\n",
    "\n",
    "criteria[4, 1] <- rets_ar9$aic\n",
    "criteria[4, 2] <- rets_ar9$bic\n",
    "criteria[5, 1] <- rets_arma42$aic\n",
    "criteria[5, 2] <- rets_arma42$bic\n",
    "criteria[6, 1] <- rets_ma1$aic\n",
    "criteria[6, 2] <- rets_ma1$bic\n",
    "criteria[7, 1] <- rets_ma2$aic\n",
    "criteria[7, 2] <- rets_ma2$bic\n",
    "\n",
    "criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would choose ARMA(4,2) due to the lowest values apart from the AIC of the AR(9) model.\n",
    "\n",
    "The final plot of fitted vs actual follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot.ts(rets, ylab = NA, main = 'AR(2) fitted values')\n",
    "lines(rets_ar2$fitted, col = 'red')\n",
    "\n",
    "plot.ts(rets, ylab = NA, main = 'AR(9) fitted values')\n",
    "lines(rets_ar9$fitted, col = 'red')\n",
    "\n",
    "plot.ts(rets, ylab = NA, main = 'MA(2) fitted values')\n",
    "lines(rets_ma2$fitted, col = 'red')\n",
    "\n",
    "plot.ts(rets, ylab = NA, main = 'ARMA(4,2) fitted values')\n",
    "lines(rets_arma42$fitted, col = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# AR(2) Model\n",
    "plot.ts(rets[1:100], ylab = NA, main = 'AR(2) fitted values for first 100 observations')\n",
    "lines(rets_ar2$fitted[1:100], col = 'red')\n",
    "\n",
    "# AR(9) Model\n",
    "plot.ts(rets[1:100], ylab = NA, main = 'AR(9) fitted values for first 100 observations')\n",
    "lines(rets_ar9$fitted[1:100], col = 'red')\n",
    "\n",
    "# MA(2) Model\n",
    "plot.ts(rets[1:100], ylab = NA, main = 'MA(2) fitted values for first 100 observations')\n",
    "lines(rets_ma2$fitted[1:100], col = 'red')\n",
    "\n",
    "# ARMA(4,2) Model\n",
    "plot.ts(rets[1:100], ylab = NA, main = 'ARMA(4,2) fitted values for first 100 observations')\n",
    "lines(rets_arma42$fitted[1:100], col = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the data to two parts - since the models are fitting differently for the higher volatility period than the rest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the actual vs fitted values graphs we can see that in the cluster of the high volatility, the models seem to fit the data well. However, in the rest, the fit seems to be worse. Therefore we would divide the data to two parts and identify the models for both parts again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rets1 <- rets[1:(length(rets) / 2)]\n",
    "rets2 <- rets[((length(rets) / 2) + 1):length(rets)]\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "par(mfrow = c(2, 2))\n",
    "\n",
    "acf(rets1, main = \"First subsample\")\n",
    "pacf(rets1, main = \"First subsample\")\n",
    "acf(rets2, main = \"Second subsample\")\n",
    "pacf(rets2, main = \"Second subsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Box.test(rets1, type = 'Ljung-Box')\n",
    "\n",
    "adf.test(rets1, k = 1)\n",
    "\n",
    "kpss.test(rets1, null = 'Level')\n",
    "kpss.test(rets1, null = 'Trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Box.test(rets2, type = 'Ljung-Box')\n",
    "\n",
    "adf.test(rets2, k = 1)\n",
    "\n",
    "kpss.test(rets2, null = 'Level')\n",
    "kpss.test(rets2, null = 'Trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the B-L test on the second half of the data it is likely that there is not enough autocorrelation to be able to model the data...\n",
    "\n",
    "On the other hand the first part of the data seems to be appropriate for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first subsample we might expect similar models and results as for the whole, undivided dataset, since it seems the previous results were driven mainly by the variation in the first half of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis just of the first part of the divided dataset follows. Nevertheless, it is almost identical to the analysis of the whole dataset conducted above. Thus the following analysis is just illustrative, without any comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "# ar2\n",
    "library(forecast)\n",
    "rets1_ar2 <- Arima(rets1, order = c(2, 0, 0))\n",
    "summary (rets1_ar2)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets1_ar2$residuals, main = NA)\n",
    "pacf(rets1_ar2$residuals, main = NA)\n",
    "\n",
    "\n",
    "Box.test(rets1_ar2$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets1_ar2$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets1_ar2$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets1_ar2$residuals, type = \"Ljung-Box\", lag = 12)\n",
    "\n",
    "\n",
    "# ar4\n",
    "library(forecast)\n",
    "rets1_ar4 <- Arima(rets1, order = c(4, 0, 0))\n",
    "summary (rets1_ar4)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets1_ar4$residuals, main = NA)\n",
    "pacf(rets1_ar4$residuals, main = NA)\n",
    "\n",
    "Box.test(rets1_ar4$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets1_ar4$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets1_ar4$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets1_ar4$residuals, type = \"Ljung-Box\", lag = 12)\n",
    "\n",
    "\n",
    "\n",
    "# ar7\n",
    "library(forecast)\n",
    "rets1_ar7 <- Arima(rets1, order = c(7, 0, 0))\n",
    "summary (rets1_ar7)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets1_ar7$residuals, main = NA)\n",
    "pacf(rets1_ar7$residuals, main = NA)\n",
    "\n",
    "Box.test(rets1_ar7$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets1_ar7$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets1_ar7$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets1_ar7$residuals, type = \"Ljung-Box\", lag = 12)\n",
    "\n",
    "\n",
    "# ar9\n",
    "library(forecast)\n",
    "rets1_ar9 <- Arima(rets1, order = c(9, 0, 0))\n",
    "summary (rets1_ar9)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets1_ar9$residuals, main = NA)\n",
    "pacf(rets1_ar9$residuals, main = NA)\n",
    "\n",
    "Box.test(rets1_ar9$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets1_ar9$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets1_ar9$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets1_ar9$residuals, type = \"Ljung-Box\", lag = 12)\n",
    "\n",
    "\n",
    "\n",
    "# ma1\n",
    "library(forecast)\n",
    "rets1_ma1 <- Arima(rets1, order = c(0, 0, 1))\n",
    "summary (rets1_ma1)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets1_ma1$residuals, main = NA)\n",
    "pacf(rets1_ma1$residuals, main = NA)\n",
    "\n",
    "Box.test(rets1_ma1$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets1_ma1$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets1_ma1$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets1_ma1$residuals, type = \"Ljung-Box\", lag = 12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "auto.arima(rets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets1_ma2 <- Arima(rets1, order = c(0, 0, 2), include.mean = FALSE)\n",
    "summary(rets1_ma2)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets1_ma2$residuals, main = NA)\n",
    "pacf(rets1_ma2$residuals, main = NA)\n",
    "\n",
    "\n",
    "Box.test(rets1_ma2$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets1_ma2$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets1_ma2$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets1_ma2$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "rets1_arma42 <- Arima(rets1, order = c(4, 0, 2))\n",
    "summary (rets1_arma42)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(rets1_arma42$residuals, main = NA)\n",
    "pacf(rets1_arma42$residuals, main = NA)\n",
    "\n",
    "Box.test(rets1_arma42$residuals, type = \"Ljung-Box\", lag = 1)\n",
    "Box.test(rets1_arma42$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(rets1_arma42$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(rets1_arma42$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "models <- 7\n",
    "criteria <- matrix(ncol = 2, nrow = models)\n",
    "colnames(criteria) <- c('AIC', 'BIC')\n",
    "rownames(criteria) <- c('AR(2)','AR(4)', 'AR(7)', 'AR(9)','ARMA(4,2)','MA(1)','MA(2)')\n",
    "\n",
    "criteria[1, 1] <- rets1_ar2$aic\n",
    "criteria[1, 2] <- rets1_ar2$bic\n",
    "criteria[2, 1] <- rets1_ar4$aic\n",
    "criteria[2, 2] <- rets1_ar4$bic\n",
    "criteria[3, 1] <- rets1_ar7$aic\n",
    "criteria[3, 2] <- rets1_ar7$bic\n",
    "\n",
    "criteria[4, 1] <- rets1_ar9$aic\n",
    "criteria[4, 2] <- rets1_ar9$bic\n",
    "criteria[5, 1] <- rets1_arma42$aic\n",
    "criteria[5, 2] <- rets1_arma42$bic\n",
    "criteria[6, 1] <- rets1_ma1$aic\n",
    "criteria[6, 2] <- rets1_ma1$bic\n",
    "criteria[7, 1] <- rets1_ma2$aic\n",
    "criteria[7, 2] <- rets1_ma2$bic\n",
    "\n",
    "criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "plot.ts(rets1, ylab = NA, main = 'AR(2) fitted values')\n",
    "lines(rets1_ar2$fitted, col = 'red')\n",
    "\n",
    "plot.ts(rets1, ylab = NA, main = 'AR(9) fitted values')\n",
    "lines(rets1_ar9$fitted, col = 'red')\n",
    "\n",
    "plot.ts(rets1, ylab = NA, main = 'MA(2) fitted values')\n",
    "lines(rets1_ma2$fitted, col = 'red')\n",
    "\n",
    "plot.ts(rets1, ylab = NA, main = 'ARMA(4,2) fitted values')\n",
    "lines(rets1_arma42$fitted, col = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "# AR(2) Model\n",
    "plot.ts(rets1[1:100], ylab = NA, main = 'AR(2) fitted values for first 100 observations')\n",
    "lines(rets1_ar2$fitted[1:100], col = 'red')\n",
    "\n",
    "# AR(9) Model\n",
    "plot.ts(rets1[1:100], ylab = NA, main = 'AR(9) fitted values for first 100 observations')\n",
    "lines(rets1_ar9$fitted[1:100], col = 'red')\n",
    "\n",
    "# MA(2) Model\n",
    "plot.ts(rets1[1:100], ylab = NA, main = 'MA(2) fitted values for first 100 observations')\n",
    "lines(rets1_ma2$fitted[1:100], col = 'red')\n",
    "\n",
    "# ARMA(4,2) Model\n",
    "plot.ts(rets1[1:100], ylab = NA, main = 'ARMA(4,2) fitted values for first 100 observations')\n",
    "lines(rets1_arma42$fitted[1:100], col = 'red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
